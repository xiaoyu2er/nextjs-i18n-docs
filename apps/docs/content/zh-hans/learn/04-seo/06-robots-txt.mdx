---
source-updated-at: 2025-05-29T18:05:49.000Z
translation-updated-at: 2025-05-29T19:44:31.453Z
title: 什么是 robots.txt 文件？
headline: 'SEO：解读 robots.txt 文件'
image: >-
  https://nextjs.org/api/learn-og?title=What%20is%20a%20robots.txt%20File?&amp;chapter=6
---

[robots.txt 文件](https://developers.google.com/search/docs/advanced/robots/intro)用于告知搜索引擎爬虫可以或不能请求您网站上的哪些页面或文件。`robots.txt` 是一个网络标准文件，大多数[良性爬虫](https://www.cloudflare.com/learning/bots/how-to-manage-good-bots)在请求特定域名内容前都会先读取该文件。

您可能希望保护网站的某些区域不被爬取（从而避免被索引），例如 CMS 后台、电商用户账户或某些 API 路由等。这些文件必须部署在每个主机的根目录下，或者您可以将根路径 `/robots.txt` 重定向到目标 URL，大多数爬虫会遵循该规则。

### [如何在 Next.js 项目中添加 robots.txt 文件](#how-to-add-a-robotstxt-file-to-a-nextjs-project)

借助 Next.js 的[静态文件服务](/docs/basic-features/static-file-serving)功能，我们可以轻松添加 `robots.txt` 文件。只需在项目根目录的 `public` 文件夹中创建名为 `robots.txt` 的新文件。文件内容示例如下：

```
//robots.txt
 
# 禁止所有爬虫访问 /accounts
User-agent: *
Disallow: /accounts
 
# 允许所有爬虫访问其他路径
User-agent: *
Allow: /
```

当您使用 `yarn dev` 运行应用时，该文件将通过 [http://localhost:3000/robots.txt](http://localhost:3000/robots.txt) 地址访问。请注意 URL 中不包含 `public` 目录名。

切勿修改 public 目录名称。该目录名不可更改，是唯一用于托管静态资源的目录。

### [扩展阅读](#further-reading)

*   [Google：创建并提交 robots.txt 文件](https://developers.google.com/search/docs/advanced/robots/create-robots-txt)