---
source-updated-at: 2025-05-29T18:05:49.000Z
translation-updated-at: 2025-06-02T19:40:56.347Z
title: Что такое файл robots.txt?
headline: 'SEO: Что такое файл robots.txt?'
image: >-
  https://nextjs.org/api/learn-og?title=What%20is%20a%20robots.txt%20File?&amp;chapter=6
---

Файл [robots.txt](https://developers.google.com/search/docs/advanced/robots/intro) сообщает поисковым роботам, какие страницы или файлы они могут или не могут запрашивать с вашего сайта. Файл `robots.txt` является стандартным веб-файлом, который большинство [хороших ботов](https://www.cloudflare.com/learning/bots/how-to-manage-good-bots) обрабатывают перед запросом данных с конкретного домена.

Возможно, вы захотите защитить определённые области вашего сайта от сканирования (и, следовательно, индексации), например, вашу CMS или админ-панель, пользовательские аккаунты в интернет-магазине или некоторые API-маршруты. Эти файлы должны размещаться в корне каждого хоста, либо вы можете перенаправить путь `/robots.txt` на целевой URL, и большинство ботов последуют за ним.

### [Как добавить файл robots.txt в проект Next.js](#how-to-add-a-robotstxt-file-to-a-nextjs-project)

Благодаря [статическому обслуживанию файлов](/docs/basic-features/static-file-serving) в Next.js мы можем легко добавить файл `robots.txt`. Для этого создайте новый файл с именем `robots.txt` в папке `public` корневого каталога. Пример содержимого файла:

```
//robots.txt
 
# Запретить всем роботам доступ к /accounts
User-agent: *
Disallow: /accounts
 
# Разрешить доступ всем роботам
User-agent: *
Allow: /
```

После запуска приложения с помощью `yarn dev` файл будет доступен по адресу [http://localhost:3000/robots.txt](http://localhost:3000/robots.txt). Обратите внимание, что имя папки `public` не является частью URL.

Не переименовывайте папку public. Её название нельзя изменить — это единственная папка для обслуживания статических ресурсов.

### [Дополнительные материалы](#further-reading)

*   [Google: Создание и отправка файла `robots.txt`](https://developers.google.com/search/docs/advanced/robots/create-robots-txt)